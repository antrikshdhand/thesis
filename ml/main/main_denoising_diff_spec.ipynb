{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn.model_selection\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scripts\n",
    "from helpers import data, runners, utils, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be v2.10\n",
    "!pip show tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be v2.10\n",
    "!pip show keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(runners)\n",
    "reload(data)\n",
    "reload(utils)\n",
    "reload(generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Check whether tf is using the GPU\n",
    "utils.check_gpu_use() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "DATA_BATCH_SIZE = 16\n",
    "GPU_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_df, ships = data.get_dataset_info(path_to_root=\"../data/deepship_baseline_unnorm_mat\", ext='mat')\n",
    "\n",
    "# Filter ships which have multiple recordings\n",
    "ships_multiple_recordings = {k: v for k, v in ships.items() if len(v) > 1}\n",
    "\n",
    "# Get a list of all segments whose ships have multiple recordings\n",
    "multiple_recordings_df = all_files_df[all_files_df[\"ship_name\"].isin(ships_multiple_recordings)]\n",
    "\n",
    "multiple_recordings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train-validate-test splits\n",
    "\n",
    "train_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    multiple_recordings_df,\n",
    "    test_size=0.2,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    test_df,\n",
    "    test_size=0.5,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generators\n",
    "train_gen = generators.N2NDeepShipGenerator(\n",
    "    train_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "val_gen = generators.N2NDeepShipGenerator(\n",
    "    val_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "test_gen = generators.N2NDeepShipGenerator(\n",
    "    test_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import irfan_2020, unet_n2n, unetpro\n",
    "\n",
    "# model = irfan_2020.get_irfan_model(input_shape=(192, 192, 1))\n",
    "model = unet_n2n.get_unet_model(input_shape=(192, 192, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.99, epsilon=1e-8),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[SSIMLoss]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    filename=\"models/saved/diff_spec_denoiser_05122024/unet/training.log\",\n",
    "    separator=\",\",\n",
    "    append=False\n",
    ")\n",
    "\n",
    "backup_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir=\"models/saved/diff_spec_denoiser_05122024/unet/tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    steps_per_epoch=train_gen.get_epoch_length() // NUM_EPOCHS,\n",
    "    callbacks=[csv_logger, backup_callback],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.evaluate(\n",
    "    test_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/saved/diff_spec_denoiser_05122024/unet/unet_denoiser.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation, metrics, and visualising denoised output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "fig = utils.get_psnr_and_loss_curves(history, together=True)\n",
    "fig.savefig(\"models/saved/diff_spec_denoiser_05122024/unet/img/psnr_loss_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few samples from the test generator for visualisation and metrics calculation\n",
    "num_samples = 5 \n",
    "\n",
    "sample_X, sample_y = next(iter(test_gen))\n",
    "sample_inputs = sample_X[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "sample_outputs = sample_y[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "\n",
    "# Predict the denoised outputs\n",
    "denoised_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of sample_inputs:\", sample_inputs.shape)\n",
    "print(\"Shape of denoised_outputs:\", denoised_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "mse_score = tf.keras.losses.MeanSquaredError()(sample_inputs, denoised_outputs).numpy()\n",
    "psnr_score = utils.psnr(sample_inputs, denoised_outputs).numpy()\n",
    "ssim_score = utils.ssim(sample_inputs, denoised_outputs).numpy()\n",
    "\n",
    "print(f\"MSE on sample batch: {mse_score}\")\n",
    "print(f\"PSNR on sample batch: {psnr_score}\")\n",
    "print(f\"SSIM on sample batch: {ssim_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all outputs are normalised\n",
    "for i, output in enumerate(denoised_outputs):\n",
    "    print(f\"Sample {i+1} - Min: {np.min(output)}; Max: {np.max(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(14, num_samples * 3.5), sharex=True, sharey=True)\n",
    "\n",
    "# fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[i, 0].imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 1].imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 2].imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "axes[0, 0].set_title(f\"Input\\n\", fontsize=18)\n",
    "axes[0, 1].set_title(f\"Denoised Output\\n\", fontsize=18)\n",
    "axes[0, 2].set_title(f\"Output\\n\", fontsize=18)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "fig.savefig(f\"models/saved/diff_spec_denoiser_05122024/unet/img/combined_spectrograms.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input, output, and target spectrograms for each sample\n",
    "for i in range(num_samples):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # INPUT\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Input\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # DENOISED OUTPUT\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Denoised Output\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # TARGET\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Target\")\n",
    "    # plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
