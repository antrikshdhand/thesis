{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn.model_selection\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scripts\n",
    "from helpers import data, runners, utils, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.13.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/antrikshdhand/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages\n",
      "Requires: tensorflow-macos\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Should be v2.10\n",
    "!pip show tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.13.1\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /Users/antrikshdhand/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow-macos\n"
     ]
    }
   ],
   "source": [
    "# Should be v2.10\n",
    "!pip show keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.generators' from '/Users/antrikshdhand/Documents/github/thesis-ml/ml/main/helpers/generators.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(runners)\n",
    "reload(data)\n",
    "reload(utils)\n",
    "reload(generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU DETECTED ✓\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Check whether tf is using the GPU\n",
    "utils.check_gpu_use() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 2\n",
    "DATA_BATCH_SIZE = 16\n",
    "GPU_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship_name</th>\n",
       "      <th>class</th>\n",
       "      <th>file_path</th>\n",
       "      <th>date</th>\n",
       "      <th>seg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEA_IMP</td>\n",
       "      <td>Tug</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tug/SEA_I...</td>\n",
       "      <td>20171118</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEASPAN_EAGLE</td>\n",
       "      <td>Tug</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tug/SEASP...</td>\n",
       "      <td>20171215</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEASPAN_RAVEN</td>\n",
       "      <td>Tug</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tug/SEASP...</td>\n",
       "      <td>20171118</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEA_IMP</td>\n",
       "      <td>Tug</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tug/SEA_I...</td>\n",
       "      <td>20171201</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SEASPAN_EAGLE</td>\n",
       "      <td>Tug</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tug/SEASP...</td>\n",
       "      <td>20171202</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53493</th>\n",
       "      <td>KIRKEHOLMEN</td>\n",
       "      <td>Tanker</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tanker/KI...</td>\n",
       "      <td>20170822</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53495</th>\n",
       "      <td>CHAMPION_ISTRA</td>\n",
       "      <td>Tanker</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tanker/CH...</td>\n",
       "      <td>20171126</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53498</th>\n",
       "      <td>CHAMPION_CORNELIA</td>\n",
       "      <td>Tanker</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tanker/CH...</td>\n",
       "      <td>20160829</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53500</th>\n",
       "      <td>CHEMBULK_NEW</td>\n",
       "      <td>Tanker</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tanker/CH...</td>\n",
       "      <td>20160531</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53501</th>\n",
       "      <td>CHAMPION_ISTRA</td>\n",
       "      <td>Tanker</td>\n",
       "      <td>../data/deepship_baseline_unnorm_mat/Tanker/CH...</td>\n",
       "      <td>20161128</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37377 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ship_name   class  \\\n",
       "0                SEA_IMP     Tug   \n",
       "1          SEASPAN_EAGLE     Tug   \n",
       "3          SEASPAN_RAVEN     Tug   \n",
       "4                SEA_IMP     Tug   \n",
       "5          SEASPAN_EAGLE     Tug   \n",
       "...                  ...     ...   \n",
       "53493        KIRKEHOLMEN  Tanker   \n",
       "53495     CHAMPION_ISTRA  Tanker   \n",
       "53498  CHAMPION_CORNELIA  Tanker   \n",
       "53500       CHEMBULK_NEW  Tanker   \n",
       "53501     CHAMPION_ISTRA  Tanker   \n",
       "\n",
       "                                               file_path      date  seg  \n",
       "0      ../data/deepship_baseline_unnorm_mat/Tug/SEA_I...  20171118  158  \n",
       "1      ../data/deepship_baseline_unnorm_mat/Tug/SEASP...  20171215   11  \n",
       "3      ../data/deepship_baseline_unnorm_mat/Tug/SEASP...  20171118  198  \n",
       "4      ../data/deepship_baseline_unnorm_mat/Tug/SEA_I...  20171201  154  \n",
       "5      ../data/deepship_baseline_unnorm_mat/Tug/SEASP...  20171202  178  \n",
       "...                                                  ...       ...  ...  \n",
       "53493  ../data/deepship_baseline_unnorm_mat/Tanker/KI...  20170822  107  \n",
       "53495  ../data/deepship_baseline_unnorm_mat/Tanker/CH...  20171126   70  \n",
       "53498  ../data/deepship_baseline_unnorm_mat/Tanker/CH...  20160829   12  \n",
       "53500  ../data/deepship_baseline_unnorm_mat/Tanker/CH...  20160531  128  \n",
       "53501  ../data/deepship_baseline_unnorm_mat/Tanker/CH...  20161128   92  \n",
       "\n",
       "[37377 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_df, ships = data.get_dataset_info(path_to_root=\"../data/deepship_baseline_unnorm_mat\", ext='mat')\n",
    "\n",
    "# Filter ships which have multiple recordings\n",
    "ships_multiple_recordings = {k: v for k, v in ships.items() if len(v) > 1}\n",
    "\n",
    "# Get a list of all segments whose ships have multiple recordings\n",
    "multiple_recordings_df = all_files_df[all_files_df[\"ship_name\"].isin(ships_multiple_recordings)]\n",
    "\n",
    "multiple_recordings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train-validate-test splits\n",
    "\n",
    "train_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    multiple_recordings_df,\n",
    "    test_size=0.2,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    test_df,\n",
    "    test_size=0.5,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generators\n",
    "train_gen = generators.N2NDeepShipGenerator(\n",
    "    train_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "val_gen = generators.N2NDeepShipGenerator(\n",
    "    val_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "test_gen = generators.N2NDeepShipGenerator(\n",
    "    test_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 192, 192, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 192, 192, 64)         640       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 192, 192, 64)         0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 192, 192, 64)         36928     ['leaky_re_lu[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 192, 192, 64)         0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 96, 96, 64)           0         ['leaky_re_lu_1[0][0]']       \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 128)          73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 96, 96, 128)          0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 96, 96, 128)          147584    ['leaky_re_lu_2[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 96, 96, 128)          0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 48, 48, 128)          0         ['leaky_re_lu_3[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 48, 48, 256)          0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 48, 48, 256)          590080    ['leaky_re_lu_4[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 48, 48, 256)          0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 24, 24, 256)          0         ['leaky_re_lu_5[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 24, 24, 512)          0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 512)          2359808   ['leaky_re_lu_6[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 24, 24, 512)          0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 512)          0         ['leaky_re_lu_7[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 12, 12, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 12, 12, 1024)         0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 12, 12, 1024)         9438208   ['leaky_re_lu_8[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 12, 12, 1024)         0         ['conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 24, 24, 1024)         0         ['leaky_re_lu_9[0][0]']       \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 24, 24, 1536)         0         ['up_sampling2d[0][0]',       \n",
      "                                                                     'leaky_re_lu_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 512)          7078400   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 512)          2359808   ['leaky_re_lu_10[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 48, 48, 512)          0         ['leaky_re_lu_11[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 48, 48, 768)          0         ['up_sampling2d_1[0][0]',     \n",
      " )                                                                   'leaky_re_lu_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 48, 48, 256)          1769728   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 48, 48, 256)          590080    ['leaky_re_lu_12[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 96, 96, 256)          0         ['leaky_re_lu_13[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 96, 96, 384)          0         ['up_sampling2d_2[0][0]',     \n",
      " )                                                                   'leaky_re_lu_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 96, 96, 128)          442496    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 96, 96, 128)          147584    ['leaky_re_lu_14[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 192, 192, 128)        0         ['leaky_re_lu_15[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 192, 192, 192)        0         ['up_sampling2d_3[0][0]',     \n",
      " )                                                                   'leaky_re_lu_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 192, 192, 64)         110656    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 192, 192, 64)         36928     ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 192, 192, 1)          65        ['leaky_re_lu_17[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31377793 (119.70 MB)\n",
      "Trainable params: 31377793 (119.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models import irfan_2020, unet_n2n, unetpro\n",
    "\n",
    "# model = irfan_2020.get_irfan_model(input_shape=(192, 192, 1))\n",
    "model = unet_n2n.get_unet_model(input_shape=(192, 192, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.99, epsilon=1e-8),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[SSIMLoss]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    filename=\"models/saved/diff_spec_denoiser_05122024/unet/training.log\",\n",
    "    separator=\",\",\n",
    "    append=False\n",
    ")\n",
    "\n",
    "backup_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir=\"models/saved/diff_spec_denoiser_05122024/unet/tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPU_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackup_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[csv_logger, backup_callback],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.evaluate(\n",
    "    test_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/saved/diff_spec_denoiser_05122024/unet/unet_denoiser.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation, metrics, and visualising denoised output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "fig = utils.get_psnr_and_loss_curves(history, together=True)\n",
    "fig.savefig(\"models/saved/diff_spec_denoiser_05122024/unet/img/psnr_loss_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few samples from the test generator for visualisation and metrics calculation\n",
    "num_samples = 5 \n",
    "\n",
    "sample_X, sample_y = next(iter(test_gen))\n",
    "sample_inputs = sample_X[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "sample_outputs = sample_y[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "\n",
    "# Predict the denoised outputs\n",
    "denoised_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of sample_inputs:\", sample_inputs.shape)\n",
    "print(\"Shape of denoised_outputs:\", denoised_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "mse_score = tf.keras.losses.MeanSquaredError()(sample_inputs, denoised_outputs).numpy()\n",
    "psnr_score = utils.psnr(sample_inputs, denoised_outputs).numpy()\n",
    "\n",
    "print(f\"MSE on sample batch: {mse_score}\")\n",
    "print(f\"PSNR on sample batch: {psnr_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all outputs are normalised\n",
    "for i, output in enumerate(denoised_outputs):\n",
    "    print(f\"Sample {i+1} - Min: {np.min(output)}; Max: {np.max(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(14, num_samples * 3.5), sharex=True, sharey=True)\n",
    "\n",
    "# fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[i, 0].imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 1].imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 2].imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "axes[0, 0].set_title(f\"Input\\n\", fontsize=18)\n",
    "axes[0, 1].set_title(f\"Denoised Output\\n\", fontsize=18)\n",
    "axes[0, 2].set_title(f\"Output\\n\", fontsize=18)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "fig.savefig(f\"models/saved/diff_spec_denoiser_05122024/unet/img/combined_spectrograms.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input, output, and target spectrograms for each sample\n",
    "for i in range(num_samples):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # INPUT\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Input\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # DENOISED OUTPUT\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Denoised Output\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # TARGET\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Target\")\n",
    "    # plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
