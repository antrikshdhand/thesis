{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn.model_selection\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Scripts\n",
    "from helpers import data, runners, utils, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.10.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, Should, be, v2.10\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.10.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: keras-tuner, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, Should, be, v2.10\n"
     ]
    }
   ],
   "source": [
    "!pip show keras # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.utils' from 'c:\\\\Users\\\\sonar\\\\Desktop\\\\thesis-ml\\\\ml\\\\main\\\\helpers\\\\utils.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(runners)\n",
    "reload(data)\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU DETECTED âœ“\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Check whether tf is using the GPU\n",
    "utils.check_gpu_use() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "DATA_BATCH_SIZE = 16\n",
    "GPU_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12880, 5)\n"
     ]
    }
   ],
   "source": [
    "pairs_df = pd.read_csv(\"../data/DATASET_CSVS/deepship_pairs_diff_recording.csv\")\n",
    "\n",
    "print(pairs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship_name</th>\n",
       "      <th>file_path_1</th>\n",
       "      <th>date_seg_1</th>\n",
       "      <th>file_path_2</th>\n",
       "      <th>date_seg_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALFRED_N</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170326_1</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170403_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALFRED_N</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170326_2</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170403_48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ship_name                                        file_path_1  date_seg_1  \\\n",
       "0  ALFRED_N  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170326_1   \n",
       "1  ALFRED_N  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170326_2   \n",
       "\n",
       "                                         file_path_2   date_seg_2  \n",
       "0  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170403_51  \n",
       "1  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170403_48  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD RELATIVE PATH\n",
    "\n",
    "PATH_TO_ROOT = \"..\\\\data\\\\\"\n",
    "pairs_df[\"file_path_1\"] = pairs_df[\"file_path_1\"].apply(\n",
    "    lambda x: PATH_TO_ROOT + x\n",
    ")\n",
    "pairs_df[\"file_path_2\"] = pairs_df[\"file_path_2\"].apply(\n",
    "    lambda x: PATH_TO_ROOT + x\n",
    ")\n",
    "\n",
    "pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train-validate-test splits\n",
    "\n",
    "train_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    pairs_df,\n",
    "    test_size=0.2,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_df, test_df = sklearn.model_selection.train_test_split(\n",
    "    test_df,\n",
    "    test_size=0.5,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generators\n",
    "train_gen = generators.N2NGenerator(\n",
    "    train_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "val_gen = generators.N2NGenerator(\n",
    "    val_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "test_gen = generators.N2NGenerator(\n",
    "    test_df,\n",
    "    'mat',\n",
    "    'Ptrans',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 192, 192, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 192, 192, 64  640         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 192, 192, 64  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 192, 192, 64  36928       ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 192, 192, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 96, 96, 64)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 96, 96, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 96, 96, 128)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 96, 96, 128)  147584      ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 96, 96, 128)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 48, 48, 128)  0          ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 48, 48, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 48, 48, 256)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 48, 48, 256)  590080      ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 48, 48, 256)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 24, 24, 256)  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 24, 24, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 24, 24, 512)  0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 24, 24, 512)  2359808     ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 24, 24, 512)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 512)  0          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 12, 12, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 12, 12, 1024  0           ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 12, 12, 1024  9438208     ['leaky_re_lu_8[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 12, 12, 1024  0           ['conv2d_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 24, 24, 1024  0           ['leaky_re_lu_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 24, 24, 1536  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 24, 24, 512)  7078400     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 24, 24, 512)  0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 24, 24, 512)  2359808     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 24, 24, 512)  0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 48, 48, 512)  0          ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 48, 48, 768)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 48, 256)  1769728     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 48, 48, 256)  0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 48, 256)  590080      ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 48, 48, 256)  0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 96, 96, 256)  0          ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 96, 96, 384)  0           ['up_sampling2d_2[0][0]',        \n",
      "                                                                  'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 96, 96, 128)  442496      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 96, 96, 128)  0           ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 96, 96, 128)  147584      ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 96, 96, 128)  0           ['conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 192, 192, 12  0          ['leaky_re_lu_15[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 192, 192, 19  0           ['up_sampling2d_3[0][0]',        \n",
      "                                2)                                'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 192, 192, 64  110656      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 192, 192, 64  0           ['conv2d_16[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 192, 192, 64  36928       ['leaky_re_lu_16[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 192, 192, 64  0           ['conv2d_17[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 192, 192, 1)  65          ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,377,793\n",
      "Trainable params: 31,377,793\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.saving.load_model('models/saved/n2n_finetuned_25112024/n2n_finetuned.keras')\n",
    "\n",
    "from models import irfan_2020, unet_n2n, unetpro\n",
    "\n",
    "# model = irfan_2020.get_irfan_model(input_shape=(192, 192, 1))\n",
    "model = unet_n2n.get_unet_model(input_shape=(192, 192, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.99, epsilon=1e-8),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[utils.psnr]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/saved/diff_spec_denoiser_05122024/unet/{epoch:02d}.keras\",\n",
    "    monitor='val_psnr',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    filename=\"models/saved/diff_spec_denoiser_05122024/unet/training.log\",\n",
    "    separator=\",\",\n",
    "    append=False\n",
    ")\n",
    "\n",
    "backup_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir=\"models/saved/diff_spec_denoiser_05122024/unet/tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "644/644 - 1010s - loss: 0.0273 - psnr: 16.1409 - val_loss: 0.0231 - val_psnr: 16.6583 - 1010s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "644/644 - 1232s - loss: 0.0233 - psnr: 16.6527 - val_loss: 0.0225 - val_psnr: 16.7866 - 1232s/epoch - 2s/step\n",
      "Epoch 3/50\n",
      "644/644 - 1364s - loss: 0.0226 - psnr: 16.7806 - val_loss: 0.0221 - val_psnr: 16.8391 - 1364s/epoch - 2s/step\n",
      "Epoch 4/50\n",
      "644/644 - 1211s - loss: 0.0222 - psnr: 16.8497 - val_loss: 0.0227 - val_psnr: 16.7307 - 1211s/epoch - 2s/step\n",
      "Epoch 5/50\n",
      "644/644 - 1089s - loss: 0.0220 - psnr: 16.8799 - val_loss: 0.0218 - val_psnr: 16.9186 - 1089s/epoch - 2s/step\n",
      "Epoch 6/50\n",
      "644/644 - 1104s - loss: 0.0218 - psnr: 16.9165 - val_loss: 0.0216 - val_psnr: 16.9355 - 1104s/epoch - 2s/step\n",
      "Epoch 7/50\n",
      "644/644 - 1338s - loss: 0.0217 - psnr: 16.9411 - val_loss: 0.0215 - val_psnr: 16.9623 - 1338s/epoch - 2s/step\n",
      "Epoch 8/50\n",
      "644/644 - 1418s - loss: 0.0215 - psnr: 16.9707 - val_loss: 0.0215 - val_psnr: 16.9700 - 1418s/epoch - 2s/step\n",
      "Epoch 9/50\n",
      "644/644 - 1412s - loss: 0.0213 - psnr: 16.9993 - val_loss: 0.0217 - val_psnr: 16.9538 - 1412s/epoch - 2s/step\n",
      "Epoch 10/50\n",
      "644/644 - 1372s - loss: 0.0213 - psnr: 17.0088 - val_loss: 0.0212 - val_psnr: 17.0180 - 1372s/epoch - 2s/step\n",
      "Epoch 11/50\n",
      "644/644 - 1378s - loss: 0.0212 - psnr: 17.0277 - val_loss: 0.0213 - val_psnr: 16.9613 - 1378s/epoch - 2s/step\n",
      "Epoch 12/50\n",
      "644/644 - 1377s - loss: 0.0210 - psnr: 17.0509 - val_loss: 0.0215 - val_psnr: 16.9972 - 1377s/epoch - 2s/step\n",
      "Epoch 13/50\n",
      "644/644 - 1406s - loss: 0.0209 - psnr: 17.0670 - val_loss: 0.0210 - val_psnr: 17.0375 - 1406s/epoch - 2s/step\n",
      "Epoch 14/50\n",
      "644/644 - 1456s - loss: 0.0209 - psnr: 17.0778 - val_loss: 0.0210 - val_psnr: 17.0670 - 1456s/epoch - 2s/step\n",
      "Epoch 15/50\n",
      "644/644 - 1444s - loss: 0.0208 - psnr: 17.0919 - val_loss: 0.0216 - val_psnr: 16.9699 - 1444s/epoch - 2s/step\n",
      "Epoch 16/50\n",
      "644/644 - 1437s - loss: 0.0207 - psnr: 17.1183 - val_loss: 0.0210 - val_psnr: 17.0616 - 1437s/epoch - 2s/step\n",
      "Epoch 17/50\n",
      "644/644 - 1449s - loss: 0.0206 - psnr: 17.1263 - val_loss: 0.0210 - val_psnr: 17.0472 - 1449s/epoch - 2s/step\n",
      "Epoch 18/50\n",
      "644/644 - 1532s - loss: 0.0206 - psnr: 17.1360 - val_loss: 0.0207 - val_psnr: 17.0983 - 1532s/epoch - 2s/step\n",
      "Epoch 19/50\n",
      "644/644 - 1819s - loss: 0.0204 - psnr: 17.1620 - val_loss: 0.0209 - val_psnr: 17.0752 - 1819s/epoch - 3s/step\n",
      "Epoch 20/50\n",
      "644/644 - 1842s - loss: 0.0203 - psnr: 17.1763 - val_loss: 0.0212 - val_psnr: 16.9998 - 1842s/epoch - 3s/step\n",
      "Epoch 21/50\n",
      "644/644 - 1849s - loss: 0.0203 - psnr: 17.1899 - val_loss: 0.0207 - val_psnr: 17.1013 - 1849s/epoch - 3s/step\n",
      "Epoch 22/50\n",
      "644/644 - 1870s - loss: 0.0201 - psnr: 17.2134 - val_loss: 0.0206 - val_psnr: 17.1217 - 1870s/epoch - 3s/step\n",
      "Epoch 23/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, csv_logger, backup_callback],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.evaluate(\n",
    "    test_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/saved/diff_spec_denoiser_05122024/unet/unet_denoiser.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation, metrics, and visualising denoised output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "fig = utils.get_psnr_and_loss_curves(history, together=True)\n",
    "fig.savefig(\"models/saved/diff_spec_denoiser_05122024/unet/img/psnr_loss_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few samples from the test generator for visualisation and metrics calculation\n",
    "num_samples = 5 \n",
    "\n",
    "sample_X, sample_y = next(iter(test_gen))\n",
    "sample_inputs = sample_X[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "sample_outputs = sample_y[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "\n",
    "# Predict the denoised outputs\n",
    "denoised_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of sample_inputs:\", sample_inputs.shape)\n",
    "print(\"Shape of denoised_outputs:\", denoised_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "mse_score = tf.keras.losses.MeanSquaredError()(sample_inputs, denoised_outputs).numpy()\n",
    "psnr_score = utils.psnr(sample_inputs, denoised_outputs).numpy()\n",
    "\n",
    "print(f\"MSE on sample batch: {mse_score}\")\n",
    "print(f\"PSNR on sample batch: {psnr_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all outputs are normalised\n",
    "for i, output in enumerate(denoised_outputs):\n",
    "    print(f\"Sample {i+1} - Min: {np.min(output)}; Max: {np.max(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(14, num_samples * 3.5), sharex=True, sharey=True)\n",
    "\n",
    "# fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[i, 0].imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 1].imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 2].imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "axes[0, 0].set_title(f\"Input\\n\", fontsize=18)\n",
    "axes[0, 1].set_title(f\"Denoised Output\\n\", fontsize=18)\n",
    "axes[0, 2].set_title(f\"Output\\n\", fontsize=18)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "fig.savefig(f\"models/saved/diff_spec_denoiser_05122024/unet/img/combined_spectrograms.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input, output, and target spectrograms for each sample\n",
    "for i in range(num_samples):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # INPUT\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Input\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # DENOISED OUTPUT\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Denoised Output\")\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # TARGET\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Target\")\n",
    "    # plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acml_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
