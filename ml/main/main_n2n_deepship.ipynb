{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Scripts\n",
    "from helpers import data, runners, utils, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.13.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Users/antrikshdhand/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages\n",
      "Requires: tensorflow-macos\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras\n",
      "Version: 2.13.1\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: /Users/antrikshdhand/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: tensorflow-macos\n"
     ]
    }
   ],
   "source": [
    "!pip show keras # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.utils' from '/Users/antrikshdhand/Documents/github/thesis-ml/ml/main/helpers/utils.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(runners)\n",
    "reload(data)\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU DETECTED âœ“\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Check whether tf is using the GPU\n",
    "utils.check_gpu_use() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BATCH_SIZE = 16\n",
    "GPU_BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12880, 5)\n"
     ]
    }
   ],
   "source": [
    "pairs_df = pd.read_csv(\"../data/DATASET_CSVS/deepship_pairs_diff_recording.csv\")\n",
    "\n",
    "print(pairs_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ship_name</th>\n",
       "      <th>file_path_1</th>\n",
       "      <th>date_seg_1</th>\n",
       "      <th>file_path_2</th>\n",
       "      <th>date_seg_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALFRED_N</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170326_1</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170403_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALFRED_N</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170326_2</td>\n",
       "      <td>..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...</td>\n",
       "      <td>20170403_48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ship_name                                        file_path_1  date_seg_1  \\\n",
       "0  ALFRED_N  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170326_1   \n",
       "1  ALFRED_N  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170326_2   \n",
       "\n",
       "                                         file_path_2   date_seg_2  \n",
       "0  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170403_51  \n",
       "1  ..\\data\\deepship_baseline_mat\\Tanker\\ALFRED_N-...  20170403_48  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD RELATIVE PATH\n",
    "\n",
    "PATH_TO_ROOT = \"..\\\\data\\\\\"\n",
    "pairs_df[\"file_path_1\"] = pairs_df[\"file_path_1\"].apply(\n",
    "    lambda x: PATH_TO_ROOT + x\n",
    ")\n",
    "pairs_df[\"file_path_2\"] = pairs_df[\"file_path_2\"].apply(\n",
    "    lambda x: PATH_TO_ROOT + x\n",
    ")\n",
    "\n",
    "pairs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing split\n",
    "train, test = train_test_split(\n",
    "    pairs_df,\n",
    "    test_size=0.2,\n",
    "    random_state=100,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generators\n",
    "train_gen = generators.N2NGenerator(\n",
    "    train,\n",
    "    'mat',\n",
    "    'Pexp',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")\n",
    "\n",
    "test_gen = generators.N2NGenerator(\n",
    "    test,\n",
    "    'mat',\n",
    "    'Pexp',\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 192, 192, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 192, 192, 64)         640       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 192, 192, 64)         36928     ['leaky_re_lu_18[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 96, 96, 64)           0         ['leaky_re_lu_19[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 96, 96, 128)          73856     ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 96, 96, 128)          147584    ['leaky_re_lu_20[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 48, 48, 128)          0         ['leaky_re_lu_21[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 48, 48, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 48, 48, 256)          590080    ['leaky_re_lu_22[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 24, 24, 256)          0         ['leaky_re_lu_23[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 24, 24, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 24, 24, 512)          2359808   ['leaky_re_lu_24[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 12, 12, 512)          0         ['leaky_re_lu_25[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 12, 12, 1024)         4719616   ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 12, 12, 1024)         0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 12, 12, 1024)         9438208   ['leaky_re_lu_26[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 12, 12, 1024)         0         ['conv2d_28[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 24, 24, 1024)         0         ['leaky_re_lu_27[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 24, 24, 1536)         0         ['up_sampling2d_4[0][0]',     \n",
      " )                                                                   'leaky_re_lu_25[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 24, 24, 512)          7078400   ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 24, 24, 512)          2359808   ['leaky_re_lu_28[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 24, 24, 512)          0         ['conv2d_30[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 48, 48, 512)          0         ['leaky_re_lu_29[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 48, 48, 768)          0         ['up_sampling2d_5[0][0]',     \n",
      " )                                                                   'leaky_re_lu_23[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 48, 48, 256)          1769728   ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 48, 48, 256)          590080    ['leaky_re_lu_30[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 48, 48, 256)          0         ['conv2d_32[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 96, 96, 256)          0         ['leaky_re_lu_31[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 96, 96, 384)          0         ['up_sampling2d_6[0][0]',     \n",
      " )                                                                   'leaky_re_lu_21[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 96, 96, 128)          442496    ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 96, 96, 128)          147584    ['leaky_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 96, 96, 128)          0         ['conv2d_34[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSamplin  (None, 192, 192, 128)        0         ['leaky_re_lu_33[0][0]']      \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 192, 192, 192)        0         ['up_sampling2d_7[0][0]',     \n",
      " )                                                                   'leaky_re_lu_19[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 192, 192, 64)         110656    ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " leaky_re_lu_34 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 192, 192, 64)         36928     ['leaky_re_lu_34[0][0]']      \n",
      "                                                                                                  \n",
      " leaky_re_lu_35 (LeakyReLU)  (None, 192, 192, 64)         0         ['conv2d_36[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 192, 192, 1)          65        ['leaky_re_lu_35[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31377793 (119.70 MB)\n",
      "Trainable params: 31377793 (119.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = keras.saving.load_model('models/saved/n2n_finetuned_25112024/n2n_finetuned.keras')\n",
    "\n",
    "from models import unet_n2n\n",
    "\n",
    "# model = unetpro.get_unetpro_model(\n",
    "#     input_size=(192, 192, 1), \n",
    "#     classes=1, # Use 1 for denoising\n",
    "#     dropout=0.2\n",
    "# ) \n",
    "\n",
    "# model = unet.get_unet_model(\n",
    "#     input_size=(192, 192, 1),\n",
    "#     classes=1,\n",
    "#     dropout=0.5\n",
    "# )\n",
    "\n",
    "model = unet_n2n.get_unet_model(input_shape=(192, 192, 1), channels=1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[psnr]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\deepship_baseline_mat\\\\Passengership\\\\QUEEN_OF-60-20160831_seg019.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# [DBS=16, GBS=4] Entire dataset + 1 epoch = 24 min\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# [DBS=16, GBS=4] Entire dataset + 10 epochs = 235 min\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPU_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/main/helpers/generators.py:184\u001b[0m, in \u001b[0;36mN2NGenerator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mGenerate one batch of data.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    182\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:(index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/main/helpers/generators.py:166\u001b[0m, in \u001b[0;36mN2NGenerator.__get_data\u001b[0;34m(self, batch_df)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mLoad and preprocess both X and y spectrograms for the batch. \u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mX and y are different spectrograms from the same vessel, used for denoising.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# First convert X spectrogram\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m \u001b[43mimport_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_var_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_var_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msource_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_path_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspec_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Then convert y spectrogram\u001b[39;00m\n\u001b[1;32m    169\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m import_spectrogram(batch_df, ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mext, mat_var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat_var_name,\n\u001b[1;32m    170\u001b[0m                               source_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path_2\u001b[39m\u001b[38;5;124m'\u001b[39m, dest_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec_2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/main/helpers/data.py:154\u001b[0m, in \u001b[0;36mimport_spectrogram\u001b[0;34m(df, ext, mat_var_name, source_col, dest_col)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mat_var_name:\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide MAT variable name if ext=mat.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[:, dest_col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmat_var_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file extension. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/main/helpers/data.py:155\u001b[0m, in \u001b[0;36mimport_spectrogram.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mat_var_name:\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide MAT variable name if ext=mat.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[:, dest_col] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, source_col]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[mat_var_name]\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file extension. Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/Documents/github/thesis-ml/ml/virt/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_like, mode), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\deepship_baseline_mat\\\\Passengership\\\\QUEEN_OF-60-20160831_seg019.mat'"
     ]
    }
   ],
   "source": [
    "# [DBS=16, GBS=4] Entire dataset + 1 epoch = 24 min\n",
    "# [DBS=16, GBS=4] Entire dataset + 10 epochs = 235 min\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.evaluate(\n",
    "    test_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/saved/unet_denoiser_11112024/unet_denoiser.keras')\n",
    "model.save('models/saved/unetpro_denoiser_13112024/unetpro_denoiser_10_epochs.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation, metrics, and visualising denoised output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few samples from the test generator for visualisation and metrics calculation\n",
    "num_samples = 5 \n",
    "\n",
    "sample_X, sample_y = next(iter(test_gen))\n",
    "sample_inputs = sample_X[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "sample_outputs = sample_y[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "\n",
    "# Predict the denoised outputs\n",
    "denoised_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "mse_score = tf.keras.losses.MeanSquaredError()(sample_inputs, denoised_outputs).numpy()\n",
    "psnr_score = psnr(sample_inputs, denoised_outputs).numpy()\n",
    "\n",
    "print(f\"MSE on sample batch: {mse_score}\")\n",
    "print(f\"PSNR on sample batch: {psnr_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all outputs are normalised\n",
    "for i, output in enumerate(denoised_outputs):\n",
    "    print(f\"Sample {i+1} - Min: {np.min(output)}; Max: {np.max(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input, output, and target spectrograms for each sample\n",
    "for i in range(num_samples):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # INPUT\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Input\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # DENOISED OUTPUT\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Denoised Output\")\n",
    "    plt.colorbar()\n",
    "    plt.clim(0, 1)\n",
    "\n",
    "    # TARGET\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(sample_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Target\")\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
