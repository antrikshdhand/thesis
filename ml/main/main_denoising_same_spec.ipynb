{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from importlib import reload\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scripts\n",
    "from helpers import data, runners, utils, generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.10.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, Should, be, v2.10\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: keras"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #, Should, be, v2.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Version: 2.10.0\n",
      "Summary: Deep learning for humans.\n",
      "Home-page: https://keras.io/\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: keras-tuner, tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip show keras # Should be v2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helpers.generators' from 'c:\\\\Users\\\\sonar\\\\Desktop\\\\thesis-ml\\\\ml\\\\main\\\\helpers\\\\generators.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(runners)\n",
    "reload(data)\n",
    "reload(utils)\n",
    "reload(generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU DETECTED âœ“\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# Check whether tf is using the GPU\n",
    "utils.check_gpu_use() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FOLDS = 10\n",
    "NUM_EPOCHS = 50\n",
    "DATA_BATCH_SIZE = 16\n",
    "GPU_BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dfs = data.get_fold_dfs(\n",
    "    fold_definition_csv=\"../data/DATASET_CSVS/deepship_5k_seg_3s.csv\",\n",
    "    new_path_to_root=\"../data/deepship_baseline_unnorm_mat\",\n",
    "    ext=\"mat\", \n",
    "    n_folds=NUM_FOLDS,\n",
    "    unix=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43470, 5)\n",
      "(4534, 5)\n",
      "(5498, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = data.generate_kth_fold(fold_dfs, test_idx=1, val_idx=0)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "del fold_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generators.DeepShipGenerator(\n",
    "    df=train_df,\n",
    "    ext=\"mat\",\n",
    "    mat_var_name=\"Ptrans\",\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    conv_channel=True,\n",
    "    zero_one_normalised=True,\n",
    "    X_only=True\n",
    ")\n",
    "\n",
    "val_gen = generators.DeepShipGenerator(\n",
    "    df=val_df,\n",
    "    ext=\"mat\",\n",
    "    mat_var_name=\"Ptrans\",\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    conv_channel=True,\n",
    "    zero_one_normalised=True,\n",
    "    X_only=True\n",
    ")\n",
    "\n",
    "test_gen = generators.DeepShipGenerator(\n",
    "    df=test_df,\n",
    "    ext=\"mat\",\n",
    "    mat_var_name=\"Ptrans\",\n",
    "    batch_size=DATA_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    conv_channel=True,\n",
    "    zero_one_normalised=True,\n",
    "    X_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"irfan_2020\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 192, 192, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 192, 192, 64)      640       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 192, 192, 64)      0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 192, 192, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 96, 96, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 64)        36928     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 96, 96, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 96, 96, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 128)       73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 48, 48, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 48, 48, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 24, 24, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 24, 24, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 24, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " encoder_output (MaxPooling2  (None, 12, 12, 256)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 12, 12, 256)      590080    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 24, 24, 256)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 24, 24, 128)      295040    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 48, 48, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 48, 48, 64)       73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 96, 96, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 96, 96, 64)       36928     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 96, 96, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 96, 96, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 192, 192, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 192, 192, 1)      577       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Activation)  (None, 192, 192, 1)      0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,407,105\n",
      "Trainable params: 1,405,057\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models import irfan_2020\n",
    "\n",
    "model = irfan_2020.get_irfan_model(input_shape=(192, 192, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.99, epsilon=1e-8),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[utils.psnr]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"models/saved/same_spec_denoiser_05122024/irfan/{epoch:02d}.keras\",\n",
    "    monitor='val_psnr',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "csv_logger = keras.callbacks.CSVLogger(\n",
    "    filename=\"models/saved/same_spec_denoiser_05122024/irfan/training.log\",\n",
    "    separator=\",\",\n",
    "    append=False\n",
    ")\n",
    "\n",
    "backup_callback = keras.callbacks.BackupAndRestore(\n",
    "    backup_dir=\"models/saved/same_spec_denoiser_05122024/irfan/tmp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPU_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackup_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;241m=\u001b[39m data_handler\u001b[38;5;241m.\u001b[39m_initial_step \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\sonar\\anaconda3v2\\envs\\acml_2024\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, csv_logger, backup_callback],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.evaluate(\n",
    "    test_gen,\n",
    "    batch_size=GPU_BATCH_SIZE,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/saved/same_spec_denoiser_05122024/irfan/irfan_denoiser.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation, metrics, and visualising denoised output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "fig = utils.get_psnr_and_loss_curves(history, together=True)\n",
    "fig.savefig(\"models/saved/same_spec_denoiser_05122024/irfan/img/psnr_loss_curves.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few samples from the test generator for visualisation and metrics calculation\n",
    "num_samples = 5 \n",
    "\n",
    "sample_batch = next(iter(test_gen))[0]\n",
    "sample_inputs = sample_batch[:num_samples]  # Extract the first `num_samples` examples from the batch\n",
    "\n",
    "# Predict the denoised outputs\n",
    "denoised_outputs = model.predict(sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "mse_score = tf.keras.losses.MeanSquaredError()(sample_inputs, denoised_outputs).numpy()\n",
    "psnr_score = utils.psnr(sample_inputs, denoised_outputs).numpy()\n",
    "\n",
    "print(f\"MSE on sample batch: {mse_score}\")\n",
    "print(f\"PSNR on sample batch: {psnr_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, output in enumerate(denoised_outputs):\n",
    "    print(f\"Sample {i+1} - Min: {np.min(output)}; Max: {np.max(output)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure\n",
    "fig, axes = plt.subplots(num_samples, 2, figsize=(12, num_samples * 3.5), sharex=True, sharey=True)\n",
    "\n",
    "# fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    axes[i, 0].imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    axes[i, 1].imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "\n",
    "axes[0, 0].set_title(f\"Noisy Input\\n\", fontsize=18)\n",
    "axes[0, 1].set_title(f\"Denoised Output\\n\", fontsize=18)\n",
    "\n",
    "fig.tight_layout(pad=1.5)\n",
    "fig.savefig(f\"models/saved/same_spec_denoiser_05122024/irfan/img/combined_spectrograms.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the input, output, and target spectrograms for each sample\n",
    "for i in range(num_samples):\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Noisy Input\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(sample_inputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Noisy Input\", fontdict={'size': 16})\n",
    "    # plt.colorbar()\n",
    "\n",
    "    # Denoised Output\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(denoised_outputs[i].squeeze(), cmap=\"viridis\", aspect=\"auto\")\n",
    "    plt.title(\"Denoised Output\", fontdict={'size': 16})\n",
    "    # plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f\"models/saved/same_spec_denoiser_05122024/irfan/img/ex{i + 1}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acml_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
