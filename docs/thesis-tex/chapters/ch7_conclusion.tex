\chapter{Conclusion}

This thesis explored the role of preprocessing techniques in enhancing feature representations for \acrshort{uatr}, with a focus on three key methods: normalisation, detrending, and denoising. Using the DeepShip dataset and a CNN-LSTM architecture as the benchmark classifier, we systematically evaluated how these preprocessing approaches could refine spectrogram inputs to improve classification performance.

The hybrid CNN-LSTM model was selected as the baseline classifier due to its ability to capture both spatial and temporal features from spectrograms effectively. The DeepShip dataset was segmented into three-second intervals and organised into 10 folds for $k$-fold cross-validation. The model achieved a baseline accuracy of 63.41\%, establishing a robust reference point for assessing the influence of the preprocessing techniques on classification performance.

The normalisation experiment demonstrated that both channel-based and global normalisation had minimal impact on classification performance. This is likely due to the consistent feature scales already present in the DeepShip dataset, resulting from its controlled recording conditions and the logarithmic transformation inherent in power spectrogram preprocessing. These findings suggest that normalisation might have a greater impact on datasets with more variability, such as those collected using dynamic towed arrays or in acoustically diverse environments.

The detrending experiment assessed the effectiveness of the $\ell_1$ detrending algorithm in suppressing long-term trends and isolating short-term fluctuations within spectrograms. Unfortunately, detrending consistently led to a decline in classification accuracy across all tested parameter values. Lower $\alpha$ values introduced excessive smoothing, erasing transient features essential for vessel classification, while higher $\alpha$ values inadequately suppressed broadband noise. Additionally, the erratic accuracy-loss curves observed during training indicated that detrending disrupted the spatial and temporal integrity of the spectrograms, impairing the CNN-LSTM model’s ability to converge effectively. These results suggest that while $\ell_1$ detrending has proven effective in other domains, it is not well-suited for \acrshort{uatr} tasks in its current form. Future research should investigate alternative detrending approaches, such as wavelet-based methods, and evaluate their compatibility with diverse deep learning architectures to better understand their potential in this domain.

The denoising experiments examined both the Noise2Noise framework and masking-based approaches on the DeepShip dataset. Noise2Noise performed well on natural images but failed to produce meaningful results on underwater acoustic spectrograms due to the framework’s reliance on paired noisy inputs with uncorrelated noise -- an assumption that is difficult to approximate in the underwater acoustic domain, where noise conditions vary widely. In contrast, the masking-based approach showed some promise, achieving a high binary accuracy of 93.97\% but a lower intersection-over-union score of 0.49. This indicates that while the U-Net segmentation model accurately identified many regions of interest, it failed to capture all relevant segments consistently. Future research could improve these results by using higher-resolution spectrograms, leveraging expert-curated ground-truth masks, or incorporating advanced automated masking techniques.

This thesis highlights the challenges of adapting preprocessing techniques to the underwater acoustic domain and underscores the importance of tailoring methods to the unique characteristics of sonar data. While normalisation, detrending, and denoising each showed limitations, the insights gained provide a valuable foundation for refining preprocessing strategies in future \acrshort{uatr} research.

This thesis also offers a broader reflection on the complexities of applying machine learning to underwater acoustics, particularly when treating spectrograms as analogous to natural images. Unlike natural images, which maintain a relatively consistent structure and interpretation regardless of the capturing device or environmental conditions, spectrograms are inherently variable. The very process of generating a spectrogram introduces numerous degrees of freedom, from the choice of Fourier transform parameters to the preprocessing methods employed. Moreover, natural images typically contain a finite number of interpretable objects -- such as a bird, a tree, or a car -- that can be verified against ground truth. In contrast, spectrograms represent a continuous time-frequency domain, often encompassing an unbounded number of overlapping, unidentifiable acoustic features, making the extraction of meaningful patterns significantly more challenging.

These fundamental differences underscore why applying deep learning to underwater acoustic spectrograms is more complex and inconsistent than to natural image data. Preprocessing techniques like normalisation, which are well-established and universally effective in image processing, exhibit unpredictable outcomes when applied to spectrograms. For example, the normalisation experiments in this thesis demonstrated that the recording conditions of the DeepShip dataset -- using a fixed hydrophone recording in a 1km radius -- reduced the efficacy of standard normalisation techniques. Such an issue, absent in natural image datasets, highlights just one of the unique and unpredictable challenges of preprocessing for \acrshort{uatr}.

At the outset of this thesis, the slower progress in \acrshort{uatr} compared to image-based machine learning posed a significant question: why has deep learning not yet overtaken traditional signal processing as the preferred method for underwater acoustic target recognition? This work provides direction for an answer. The variability and uncertainty inherent in underwater acoustic data demand the  human qualities of inference and problem-solving -- abilities that machines cannot yet replicate. The complexity and unique challenges of underwater acoustics render current image-based methodologies inadequate for this domain. Bridging this gap will require years of dedicated research and the development of preprocessing and machine learning techniques explicitly tailored to the underwater acoustic environment. This thesis serves as an initial step in that direction, offering valuable insights into the limitations and potential of existing approaches.

